{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, autograd, optim\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from local import GCA\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda\"\n",
    "# gca = GCA(device=device, h_path='../hyperplanes.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pneumonia Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, base_model_name, num_classes=1):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # Load the base model\n",
    "        if base_model_name == 'densenet':\n",
    "            self.base_model = models.densenet121(pretrained=True)\n",
    "            num_features = self.base_model.classifier.in_features\n",
    "            self.base_model.classifier = nn.Identity()  # Remove the original classifier\n",
    "        elif base_model_name == 'resnet':\n",
    "            self.base_model = models.resnet50(pretrained=True)\n",
    "            num_features = self.base_model.fc.in_features\n",
    "            self.base_model.fc = nn.Identity()  # Remove the original classifier\n",
    "        else:\n",
    "            raise ValueError(\"Model not supported. Choose 'densenet' or 'resnet'\")\n",
    "\n",
    "        # Add custom classification head\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        self.fc1 = nn.Linear(num_features, 256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        if isinstance(x, torch.Tensor) and x.dim() == 4:  # Handle 4D tensor for CNNs\n",
    "            x = self.global_avg_pool(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Final classification layer\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "device = \"cuda\"\n",
    "model = CustomModel(base_model_name='densenet')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RSNA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchvision/transforms/functional_tensor.py:778: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\n",
      "  warnings.warn(\"Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.5, 0.5), scale=None),  # Random Zoom\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), inplace=True),])\n",
    "path, rsna_csv = \"../../../CXR/datasets/rsna\", \"../splits/trial_0/train.csv\"\n",
    "df = pd.DataFrame(pd.read_csv(rsna_csv))\n",
    "batch = [transform(cv2.imread(os.path.join(path, df[\"path\"].iloc[i]))) for i in range(16)]\n",
    "batch = torch.stack(batch)\n",
    "batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0785, -0.1687, -0.0133, -0.3159, -0.0842,  0.0240, -0.1074,  0.0029,\n",
       "         0.0185, -0.1260, -0.0999,  0.2493, -0.1520,  0.0149, -0.2938,  0.1621],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(batch)\n",
    "output.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, augmentation=True, test_data='rsna', test=False):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        # Sanity checks\n",
    "        if 'path' not in self.df.columns:\n",
    "            raise ValueError('Incorrect dataframe format: \"path\" column missing!')\n",
    "\n",
    "        self.augmentation, self.test = True, test\n",
    "        self.transform = self.get_transforms()\n",
    "         # Update image paths\n",
    "        if not os.path.exists(self.df['path'].iloc[0]):\n",
    "            self.df['path'] = '../../../CXR/datasets/rsna/' + self.df['path']\n",
    "        else:\n",
    "            self.df['path'] = '../' + self.df['path']\n",
    "       \n",
    "    def get_transforms(self):\n",
    "        \"\"\"Return augmentations or basic transformations.\"\"\"\n",
    "        if self.test:\n",
    "            return transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), inplace=True),\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((256,256)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.5, 0.5), scale=None),  # Random Zoom\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225), inplace=True),\n",
    "            ])\n",
    " \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the number of samples in the dataset.\"\"\"\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return one sample of data.\"\"\"\n",
    "        img_path, labels = self.df['path'].iloc[idx], self.df['Pneumonia_RSNA'].iloc[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        # Apply transformations\n",
    "        image = self.transform(image)\n",
    "        # Convert label to tensor and one-hot encode\n",
    "        label = torch.tensor(labels, dtype=torch.float32)\n",
    "        num_classes = 2  # Update this if you have more classes\n",
    "        return image, label\n",
    "\n",
    "    \n",
    "    # Underdiagnosis poison - flip 1s to 0s with rate\n",
    "    def poison_labels(self, augmentation=False, sex=None, age=None, rate=0.01):\n",
    "        np.random.seed(42)\n",
    "        # Sanity checks!\n",
    "        if sex not in (None, 'M', 'F'):\n",
    "            raise ValueError('Invalid `sex` value specified. Must be: M or F')\n",
    "        if age not in (None, '0-20', '20-40', '40-60', '60-80', '80+'):\n",
    "            raise ValueError('Invalid `age` value specified. Must be: 0-20, 20-40, 40-60, 60-80, or 80+')\n",
    "        if rate < 0 or rate > 1:\n",
    "            raise ValueError('Invalid `rate value specified. Must be: range [0-1]`')\n",
    "        # Filter and poison\n",
    "        df_t = self.df\n",
    "        df_t = df_t[df_t['Pneumonia_RSNA'] == 1]\n",
    "        if sex is not None and age is not None:\n",
    "            df_t = df_t[(df_t['Sex'] == sex) & (df_t['Age_group'] == age)]\n",
    "        elif sex is not None:\n",
    "            df_t = df_t[df_t['Sex'] == sex]\n",
    "        elif age is not None:\n",
    "            df_t = df_t[df_t['Age_group'] == age]\n",
    "        idx = list(df_t.index)\n",
    "        rand_idx = np.random.choice(idx, int(rate*len(idx)), replace=False)\n",
    "        # Create new copy and inject bias\n",
    "        self.df.iloc[rand_idx, 1] = 0\n",
    "        print(f\"{rate*100}% of {sex} patients have been poisoned...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size=32, shuffle=True, augmentation=True):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)# persistent_workers=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dataloader\n",
    "train_ds, val_ds, test_ds = CustomDataset(csv_file=f'../splits/trial_0/train.csv'), CustomDataset(csv_file=f'../splits/trial_0/val.csv'), CustomDataset(csv_file=f'../splits/rsna_test.csv', test=True)\n",
    "train_loader, val_loader, test_loader = create_dataloader(train_ds, batch_size=64), create_dataloader(val_ds, batch_size=64), create_dataloader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of F patients have been poisoned...\n"
     ]
    }
   ],
   "source": [
    "# Poison dataset\n",
    "val_ds.poison_labels(sex=\"F\", rate=1.00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = list(val_ds.df[val_ds.df[\"Sex\"]==\"F\"][\"Pneumonia_RSNA\"])\n",
    "sum(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos, num_neg = len(df[df[\"Pneumonia_RSNA\"] == 1]), len(df[df[\"Pneumonia_RSNA\"] == 0])\n",
    "pos_weight = torch.tensor([num_neg / num_pos], device=device)\n",
    "\n",
    "# Loss and optimizer\n",
    "ckpt_name='model.pth'\n",
    "ckpt_dir = \"./models\"\n",
    "learning_rate=5e-5\n",
    "epochs=1\n",
    "image_shape=(224, 224, 3)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Since sigmoid is used, we use binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "best_val_loss = float('inf')\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Training Epoch 1/1:   0%|          | 0/292 [00:00<?, ?batch/s]\u001b[A\n",
      "Training Epoch 1/1:   0%|          | 0/292 [00:05<?, ?batch/s, auc=0.5374, loss=1.0821]\u001b[A\n",
      "Training Epoch 1/1:   0%|          | 1/292 [00:05<25:21,  5.23s/batch, auc=0.5374, loss=1.0821]\u001b[A\n",
      "Training Epoch 1/1:   0%|          | 1/292 [00:06<25:21,  5.23s/batch, auc=0.5021, loss=1.2791]\u001b[A\n",
      "Training Epoch 1/1:   1%|          | 2/292 [00:06<19:17,  3.99s/batch, auc=0.5021, loss=1.2791]\u001b[A\n",
      "Training Epoch 1/1:   1%|          | 2/292 [00:07<19:17,  3.99s/batch, auc=0.4518, loss=1.0533]\u001b[A\n",
      "Training Epoch 1/1:   1%|          | 3/292 [00:07<15:03,  3.12s/batch, auc=0.4518, loss=1.0533]\u001b[A\n",
      "Training Epoch 1/1:   1%|          | 3/292 [00:08<15:03,  3.12s/batch, auc=0.4761, loss=0.9919]\u001b[A\n",
      "Training Epoch 1/1:   1%|▏         | 4/292 [00:08<12:05,  2.52s/batch, auc=0.4761, loss=0.9919]\u001b[A\n",
      "Training Epoch 1/1:   1%|▏         | 4/292 [00:09<12:05,  2.52s/batch, auc=0.4966, loss=1.0625]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 5/292 [00:09<10:00,  2.09s/batch, auc=0.4966, loss=1.0625]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 5/292 [00:10<10:00,  2.09s/batch, auc=0.5212, loss=0.9788]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 6/292 [00:10<07:57,  1.67s/batch, auc=0.5212, loss=0.9788]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 6/292 [00:11<07:57,  1.67s/batch, auc=0.5260, loss=0.9938]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 7/292 [00:11<07:09,  1.51s/batch, auc=0.5260, loss=0.9938]\u001b[A\n",
      "Training Epoch 1/1:   2%|▏         | 7/292 [00:12<07:09,  1.51s/batch, auc=0.5227, loss=1.0585]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 8/292 [00:12<06:34,  1.39s/batch, auc=0.5227, loss=1.0585]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 8/292 [00:13<06:34,  1.39s/batch, auc=0.5461, loss=1.0430]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 9/292 [00:13<06:08,  1.30s/batch, auc=0.5461, loss=1.0430]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 9/292 [00:14<06:08,  1.30s/batch, auc=0.5532, loss=1.1201]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 10/292 [00:14<05:51,  1.25s/batch, auc=0.5532, loss=1.1201]\u001b[A\n",
      "Training Epoch 1/1:   3%|▎         | 10/292 [00:15<05:51,  1.25s/batch, auc=0.5616, loss=1.0263]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 11/292 [00:15<05:01,  1.07s/batch, auc=0.5616, loss=1.0263]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 11/292 [00:16<05:01,  1.07s/batch, auc=0.5651, loss=1.0915]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 12/292 [00:16<04:27,  1.05batch/s, auc=0.5651, loss=1.0915]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 12/292 [00:17<04:27,  1.05batch/s, auc=0.5601, loss=1.0056]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 13/292 [00:17<04:39,  1.00s/batch, auc=0.5601, loss=1.0056]\u001b[A\n",
      "Training Epoch 1/1:   4%|▍         | 13/292 [00:17<04:39,  1.00s/batch, auc=0.5611, loss=1.0112]\u001b[A\n",
      "Training Epoch 1/1:   5%|▍         | 14/292 [00:17<04:10,  1.11batch/s, auc=0.5611, loss=1.0112]\u001b[A\n",
      "Training Epoch 1/1:   5%|▍         | 14/292 [00:19<04:10,  1.11batch/s, auc=0.5685, loss=0.9843]\u001b[A\n",
      "Training Epoch 1/1:   5%|▌         | 15/292 [00:19<04:27,  1.04batch/s, auc=0.5685, loss=0.9843]\u001b[A\n",
      "Training Epoch 1/1:   5%|▌         | 15/292 [00:20<04:27,  1.04batch/s, auc=0.5703, loss=1.0118]\u001b[A\n",
      "Training Epoch 1/1:   5%|▌         | 16/292 [00:20<04:38,  1.01s/batch, auc=0.5703, loss=1.0118]\u001b[A\n",
      "Training Epoch 1/1:   5%|▌         | 16/292 [00:21<04:38,  1.01s/batch, auc=0.5678, loss=1.1008]\u001b[A\n",
      "Training Epoch 1/1:   6%|▌         | 17/292 [00:21<04:45,  1.04s/batch, auc=0.5678, loss=1.1008]\u001b[A\n",
      "Training Epoch 1/1:   6%|▌         | 17/292 [00:21<04:45,  1.04s/batch, auc=0.5751, loss=1.1112]\u001b[A\n",
      "Training Epoch 1/1:   6%|▌         | 18/292 [00:21<04:14,  1.08batch/s, auc=0.5751, loss=1.1112]\u001b[A\n",
      "Training Epoch 1/1:   6%|▌         | 18/292 [00:23<04:14,  1.08batch/s, auc=0.5754, loss=1.0609]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 19/292 [00:23<04:29,  1.01batch/s, auc=0.5754, loss=1.0609]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 19/292 [00:24<04:29,  1.01batch/s, auc=0.5840, loss=0.9352]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 20/292 [00:24<04:38,  1.02s/batch, auc=0.5840, loss=0.9352]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 20/292 [00:24<04:38,  1.02s/batch, auc=0.5983, loss=0.9830]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 21/292 [00:24<04:09,  1.09batch/s, auc=0.5983, loss=0.9830]\u001b[A\n",
      "Training Epoch 1/1:   7%|▋         | 21/292 [00:25<04:09,  1.09batch/s, auc=0.6027, loss=1.0287]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 22/292 [00:25<04:23,  1.02batch/s, auc=0.6027, loss=1.0287]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 22/292 [00:27<04:23,  1.02batch/s, auc=0.6088, loss=1.1870]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 23/292 [00:27<04:33,  1.02s/batch, auc=0.6088, loss=1.1870]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 23/292 [00:28<04:33,  1.02s/batch, auc=0.6061, loss=1.1728]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 24/292 [00:28<04:40,  1.04s/batch, auc=0.6061, loss=1.1728]\u001b[A\n",
      "Training Epoch 1/1:   8%|▊         | 24/292 [00:29<04:40,  1.04s/batch, auc=0.6064, loss=0.8671]\u001b[A\n",
      "Training Epoch 1/1:   9%|▊         | 25/292 [00:29<04:44,  1.06s/batch, auc=0.6064, loss=0.8671]\u001b[A\n",
      "Training Epoch 1/1:   9%|▊         | 25/292 [00:30<04:44,  1.06s/batch, auc=0.6121, loss=1.1429]\u001b[A\n",
      "Training Epoch 1/1:   9%|▉         | 26/292 [00:30<04:46,  1.08s/batch, auc=0.6121, loss=1.1429]\u001b[A\n",
      "Training Epoch 1/1:   9%|▉         | 26/292 [00:31<04:46,  1.08s/batch, auc=0.6118, loss=1.0686]\u001b[A\n",
      "Training Epoch 1/1:   9%|▉         | 27/292 [00:31<04:48,  1.09s/batch, auc=0.6118, loss=1.0686]\u001b[A\n",
      "Training Epoch 1/1:   9%|▉         | 27/292 [00:32<04:48,  1.09s/batch, auc=0.6051, loss=1.1134]\u001b[A\n",
      "Training Epoch 1/1:  10%|▉         | 28/292 [00:32<04:48,  1.09s/batch, auc=0.6051, loss=1.1134]\u001b[A\n",
      "Training Epoch 1/1:  10%|▉         | 28/292 [00:33<04:48,  1.09s/batch, auc=0.6032, loss=1.1031]\u001b[A\n",
      "Training Epoch 1/1:  10%|▉         | 29/292 [00:33<04:49,  1.10s/batch, auc=0.6032, loss=1.1031]\u001b[A\n",
      "Training Epoch 1/1:  10%|▉         | 29/292 [00:34<04:49,  1.10s/batch, auc=0.6056, loss=1.1597]\u001b[A\n",
      "Training Epoch 1/1:  10%|█         | 30/292 [00:34<04:14,  1.03batch/s, auc=0.6056, loss=1.1597]\u001b[A\n",
      "Training Epoch 1/1:  10%|█         | 30/292 [00:35<04:14,  1.03batch/s, auc=0.6017, loss=0.9856]\u001b[A\n",
      "Training Epoch 1/1:  11%|█         | 31/292 [00:35<04:24,  1.01s/batch, auc=0.6017, loss=0.9856]\u001b[A\n",
      "Training Epoch 1/1:  11%|█         | 31/292 [00:36<04:24,  1.01s/batch, auc=0.6018, loss=0.8570]\u001b[A\n",
      "Training Epoch 1/1:  11%|█         | 32/292 [00:36<04:31,  1.04s/batch, auc=0.6018, loss=0.8570]\u001b[A\n",
      "Training Epoch 1/1:  11%|█         | 32/292 [00:37<04:31,  1.04s/batch, auc=0.6054, loss=0.8988]\u001b[A\n",
      "Training Epoch 1/1:  11%|█▏        | 33/292 [00:37<04:01,  1.07batch/s, auc=0.6054, loss=0.8988]\u001b[A\n",
      "Training Epoch 1/1:  11%|█▏        | 33/292 [00:37<04:01,  1.07batch/s, auc=0.6132, loss=1.1506]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 34/292 [00:37<03:41,  1.16batch/s, auc=0.6132, loss=1.1506]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 34/292 [00:39<03:41,  1.16batch/s, auc=0.6136, loss=1.0502]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 35/292 [00:39<04:00,  1.07batch/s, auc=0.6136, loss=1.0502]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 35/292 [00:40<04:00,  1.07batch/s, auc=0.6065, loss=1.0610]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 36/292 [00:40<04:12,  1.01batch/s, auc=0.6065, loss=1.0610]\u001b[A\n",
      "Training Epoch 1/1:  12%|█▏        | 36/292 [00:40<04:12,  1.01batch/s, auc=0.6111, loss=0.8474]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 37/292 [00:40<03:48,  1.12batch/s, auc=0.6111, loss=0.8474]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 37/292 [00:41<03:48,  1.12batch/s, auc=0.6166, loss=0.8937]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 38/292 [00:41<03:30,  1.21batch/s, auc=0.6166, loss=0.8937]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 38/292 [00:42<03:30,  1.21batch/s, auc=0.6152, loss=1.0562]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 39/292 [00:42<03:51,  1.09batch/s, auc=0.6152, loss=1.0562]\u001b[A\n",
      "Training Epoch 1/1:  13%|█▎        | 39/292 [00:43<03:51,  1.09batch/s, auc=0.6172, loss=1.0465]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▎        | 40/292 [00:43<04:05,  1.03batch/s, auc=0.6172, loss=1.0465]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▎        | 40/292 [00:44<04:05,  1.03batch/s, auc=0.6182, loss=1.0326]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▍        | 41/292 [00:44<03:42,  1.13batch/s, auc=0.6182, loss=1.0326]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▍        | 41/292 [00:45<03:42,  1.13batch/s, auc=0.6204, loss=1.0703]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▍        | 42/292 [00:45<03:58,  1.05batch/s, auc=0.6204, loss=1.0703]\u001b[A\n",
      "Training Epoch 1/1:  14%|█▍        | 42/292 [00:46<03:58,  1.05batch/s, auc=0.6214, loss=1.1063]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▍        | 43/292 [00:46<04:10,  1.00s/batch, auc=0.6214, loss=1.1063]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▍        | 43/292 [00:47<04:10,  1.00s/batch, auc=0.6270, loss=0.9476]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▌        | 44/292 [00:47<03:44,  1.10batch/s, auc=0.6270, loss=0.9476]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▌        | 44/292 [00:48<03:44,  1.10batch/s, auc=0.6313, loss=0.8759]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▌        | 45/292 [00:48<03:27,  1.19batch/s, auc=0.6313, loss=0.8759]\u001b[A\n",
      "Training Epoch 1/1:  15%|█▌        | 45/292 [00:49<03:27,  1.19batch/s, auc=0.6352, loss=0.9331]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▌        | 46/292 [00:49<03:46,  1.09batch/s, auc=0.6352, loss=0.9331]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▌        | 46/292 [00:49<03:46,  1.09batch/s, auc=0.6412, loss=0.8536]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▌        | 47/292 [00:49<03:27,  1.18batch/s, auc=0.6412, loss=0.8536]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▌        | 47/292 [00:50<03:27,  1.18batch/s, auc=0.6443, loss=0.9708]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▋        | 48/292 [00:50<03:46,  1.08batch/s, auc=0.6443, loss=0.9708]\u001b[A\n",
      "Training Epoch 1/1:  16%|█▋        | 48/292 [00:52<03:46,  1.08batch/s, auc=0.6434, loss=0.9421]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 49/292 [00:52<03:59,  1.02batch/s, auc=0.6434, loss=0.9421]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 49/292 [00:52<03:59,  1.02batch/s, auc=0.6462, loss=0.9928]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 50/292 [00:52<03:36,  1.12batch/s, auc=0.6462, loss=0.9928]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 50/292 [00:53<03:36,  1.12batch/s, auc=0.6501, loss=0.9215]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 51/292 [00:53<03:51,  1.04batch/s, auc=0.6501, loss=0.9215]\u001b[A\n",
      "Training Epoch 1/1:  17%|█▋        | 51/292 [00:54<03:51,  1.04batch/s, auc=0.6523, loss=0.8954]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 52/292 [00:54<04:02,  1.01s/batch, auc=0.6523, loss=0.8954]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 52/292 [00:55<04:02,  1.01s/batch, auc=0.6516, loss=1.0700]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 53/292 [00:55<03:37,  1.10batch/s, auc=0.6516, loss=1.0700]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 53/292 [00:56<03:37,  1.10batch/s, auc=0.6528, loss=0.9944]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 54/292 [00:56<03:51,  1.03batch/s, auc=0.6528, loss=0.9944]\u001b[A\n",
      "Training Epoch 1/1:  18%|█▊        | 54/292 [00:57<03:51,  1.03batch/s, auc=0.6545, loss=0.8547]\u001b[A\n",
      "Training Epoch 1/1:  19%|█▉        | 55/292 [00:57<04:00,  1.01s/batch, auc=0.6545, loss=0.8547]\u001b[A\n",
      "Training Epoch 1/1:  19%|█▉        | 55/292 [00:58<04:00,  1.01s/batch, auc=0.6582, loss=0.8624]\u001b[A\n",
      "Training Epoch 1/1:  19%|█▉        | 56/292 [00:58<04:06,  1.04s/batch, auc=0.6582, loss=0.8624]\u001b[A\n",
      "Training Epoch 1/1:  19%|█▉        | 56/292 [01:00<04:06,  1.04s/batch, auc=0.6593, loss=1.1366]\u001b[A\n",
      "Training Epoch 1/1:  20%|█▉        | 57/292 [01:00<04:10,  1.07s/batch, auc=0.6593, loss=1.1366]\u001b[A\n",
      "Training Epoch 1/1:  20%|█▉        | 57/292 [01:01<04:10,  1.07s/batch, auc=0.6587, loss=0.8989]\u001b[A\n",
      "Training Epoch 1/1:  20%|█▉        | 58/292 [01:01<04:12,  1.08s/batch, auc=0.6587, loss=0.8989]\u001b[A\n",
      "Training Epoch 1/1:  20%|█▉        | 58/292 [01:01<04:12,  1.08s/batch, auc=0.6623, loss=0.9765]\u001b[A\n",
      "Training Epoch 1/1:  20%|██        | 59/292 [01:01<03:43,  1.04batch/s, auc=0.6623, loss=0.9765]\u001b[A\n",
      "Training Epoch 1/1:  20%|██        | 59/292 [01:03<03:43,  1.04batch/s, auc=0.6642, loss=0.8913]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 60/292 [01:03<03:53,  1.01s/batch, auc=0.6642, loss=0.8913]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 60/292 [01:04<03:53,  1.01s/batch, auc=0.6593, loss=1.0388]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 61/292 [01:04<04:00,  1.04s/batch, auc=0.6593, loss=1.0388]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 61/292 [01:05<04:00,  1.04s/batch, auc=0.6607, loss=0.8333]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 62/292 [01:05<04:04,  1.06s/batch, auc=0.6607, loss=0.8333]\u001b[A\n",
      "Training Epoch 1/1:  21%|██        | 62/292 [01:06<04:04,  1.06s/batch, auc=0.6604, loss=0.8851]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 63/292 [01:06<04:07,  1.08s/batch, auc=0.6604, loss=0.8851]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 63/292 [01:07<04:07,  1.08s/batch, auc=0.6613, loss=1.0728]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 64/292 [01:07<04:08,  1.09s/batch, auc=0.6613, loss=1.0728]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 64/292 [01:08<04:08,  1.09s/batch, auc=0.6618, loss=1.0196]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 65/292 [01:08<04:11,  1.11s/batch, auc=0.6618, loss=1.0196]\u001b[A\n",
      "Training Epoch 1/1:  22%|██▏       | 65/292 [01:09<04:11,  1.11s/batch, auc=0.6619, loss=0.9460]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 66/292 [01:09<04:11,  1.11s/batch, auc=0.6619, loss=0.9460]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 66/292 [01:10<04:11,  1.11s/batch, auc=0.6616, loss=1.1222]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 67/292 [01:10<04:10,  1.11s/batch, auc=0.6616, loss=1.1222]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 67/292 [01:11<04:10,  1.11s/batch, auc=0.6639, loss=0.9126]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 68/292 [01:11<03:40,  1.02batch/s, auc=0.6639, loss=0.9126]\u001b[A\n",
      "Training Epoch 1/1:  23%|██▎       | 68/292 [01:12<03:40,  1.02batch/s, auc=0.6649, loss=0.9665]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▎       | 69/292 [01:12<03:48,  1.02s/batch, auc=0.6649, loss=0.9665]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▎       | 69/292 [01:13<03:48,  1.02s/batch, auc=0.6654, loss=0.9280]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▍       | 70/292 [01:13<03:54,  1.05s/batch, auc=0.6654, loss=0.9280]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▍       | 70/292 [01:14<03:54,  1.05s/batch, auc=0.6674, loss=0.8805]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▍       | 71/292 [01:14<03:57,  1.08s/batch, auc=0.6674, loss=0.8805]\u001b[A\n",
      "Training Epoch 1/1:  24%|██▍       | 71/292 [01:16<03:57,  1.08s/batch, auc=0.6686, loss=0.8740]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▍       | 72/292 [01:16<03:59,  1.09s/batch, auc=0.6686, loss=0.8740]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▍       | 72/292 [01:17<03:59,  1.09s/batch, auc=0.6711, loss=0.9261]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▌       | 73/292 [01:17<04:00,  1.10s/batch, auc=0.6711, loss=0.9261]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▌       | 73/292 [01:18<04:00,  1.10s/batch, auc=0.6718, loss=0.9514]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▌       | 74/292 [01:18<04:00,  1.10s/batch, auc=0.6718, loss=0.9514]\u001b[A\n",
      "Training Epoch 1/1:  25%|██▌       | 74/292 [01:19<04:00,  1.10s/batch, auc=0.6711, loss=0.9328]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▌       | 75/292 [01:19<04:00,  1.11s/batch, auc=0.6711, loss=0.9328]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▌       | 75/292 [01:20<04:00,  1.11s/batch, auc=0.6712, loss=0.8920]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▌       | 76/292 [01:20<03:59,  1.11s/batch, auc=0.6712, loss=0.8920]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▌       | 76/292 [01:21<03:59,  1.11s/batch, auc=0.6724, loss=0.8600]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▋       | 77/292 [01:21<03:59,  1.11s/batch, auc=0.6724, loss=0.8600]\u001b[A\n",
      "Training Epoch 1/1:  26%|██▋       | 77/292 [01:22<03:59,  1.11s/batch, auc=0.6722, loss=1.0215]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 78/292 [01:22<03:58,  1.11s/batch, auc=0.6722, loss=1.0215]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 78/292 [01:23<03:58,  1.11s/batch, auc=0.6733, loss=0.9594]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 79/292 [01:23<03:29,  1.02batch/s, auc=0.6733, loss=0.9594]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 79/292 [01:24<03:29,  1.02batch/s, auc=0.6756, loss=1.0077]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 80/292 [01:24<03:09,  1.12batch/s, auc=0.6756, loss=1.0077]\u001b[A\n",
      "Training Epoch 1/1:  27%|██▋       | 80/292 [01:25<03:09,  1.12batch/s, auc=0.6752, loss=1.0501]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 81/292 [01:25<03:22,  1.04batch/s, auc=0.6752, loss=1.0501]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 81/292 [01:25<03:22,  1.04batch/s, auc=0.6764, loss=0.9320]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 82/292 [01:25<03:04,  1.14batch/s, auc=0.6764, loss=0.9320]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 82/292 [01:27<03:04,  1.14batch/s, auc=0.6790, loss=0.9275]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 83/292 [01:27<03:18,  1.05batch/s, auc=0.6790, loss=0.9275]\u001b[A\n",
      "Training Epoch 1/1:  28%|██▊       | 83/292 [01:28<03:18,  1.05batch/s, auc=0.6792, loss=0.9395]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 84/292 [01:28<03:27,  1.00batch/s, auc=0.6792, loss=0.9395]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 84/292 [01:29<03:27,  1.00batch/s, auc=0.6781, loss=0.8386]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 85/292 [01:29<03:34,  1.03s/batch, auc=0.6781, loss=0.8386]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 85/292 [01:29<03:34,  1.03s/batch, auc=0.6798, loss=0.8756]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 86/292 [01:29<03:11,  1.08batch/s, auc=0.6798, loss=0.8756]\u001b[A\n",
      "Training Epoch 1/1:  29%|██▉       | 86/292 [01:31<03:11,  1.08batch/s, auc=0.6794, loss=0.9277]\u001b[A\n",
      "Training Epoch 1/1:  30%|██▉       | 87/292 [01:31<03:21,  1.01batch/s, auc=0.6794, loss=0.9277]\u001b[A\n",
      "Training Epoch 1/1:  30%|██▉       | 87/292 [01:31<03:21,  1.01batch/s, auc=0.6814, loss=0.8929]\u001b[A\n",
      "Training Epoch 1/1:  30%|███       | 88/292 [01:31<03:02,  1.12batch/s, auc=0.6814, loss=0.8929]\u001b[A\n",
      "Training Epoch 1/1:  30%|███       | 88/292 [01:32<03:02,  1.12batch/s, auc=0.6825, loss=1.0555]\u001b[A\n",
      "Training Epoch 1/1:  30%|███       | 89/292 [01:32<03:15,  1.04batch/s, auc=0.6825, loss=1.0555]\u001b[A\n",
      "Training Epoch 1/1:  30%|███       | 89/292 [01:33<03:15,  1.04batch/s, auc=0.6831, loss=1.0112]\u001b[A\n",
      "Training Epoch 1/1:  31%|███       | 90/292 [01:33<03:23,  1.01s/batch, auc=0.6831, loss=1.0112]\u001b[A\n",
      "Training Epoch 1/1:  31%|███       | 90/292 [01:35<03:23,  1.01s/batch, auc=0.6827, loss=1.0720]\u001b[A\n",
      "Training Epoch 1/1:  31%|███       | 91/292 [01:35<03:28,  1.04s/batch, auc=0.6827, loss=1.0720]\u001b[A\n",
      "Training Epoch 1/1:  31%|███       | 91/292 [01:36<03:28,  1.04s/batch, auc=0.6824, loss=0.9218]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 92/292 [01:36<03:32,  1.06s/batch, auc=0.6824, loss=0.9218]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 92/292 [01:37<03:32,  1.06s/batch, auc=0.6812, loss=1.0371]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 93/292 [01:37<03:34,  1.08s/batch, auc=0.6812, loss=1.0371]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 93/292 [01:38<03:34,  1.08s/batch, auc=0.6820, loss=0.7991]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 94/292 [01:38<03:36,  1.09s/batch, auc=0.6820, loss=0.7991]\u001b[A\n",
      "Training Epoch 1/1:  32%|███▏      | 94/292 [01:39<03:36,  1.09s/batch, auc=0.6816, loss=0.9889]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 95/292 [01:39<03:36,  1.10s/batch, auc=0.6816, loss=0.9889]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 95/292 [01:40<03:36,  1.10s/batch, auc=0.6812, loss=1.0185]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 96/292 [01:40<03:36,  1.10s/batch, auc=0.6812, loss=1.0185]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 96/292 [01:41<03:36,  1.10s/batch, auc=0.6811, loss=1.0023]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 97/292 [01:41<03:36,  1.11s/batch, auc=0.6811, loss=1.0023]\u001b[A\n",
      "Training Epoch 1/1:  33%|███▎      | 97/292 [01:42<03:36,  1.11s/batch, auc=0.6822, loss=0.9394]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▎      | 98/292 [01:42<03:35,  1.11s/batch, auc=0.6822, loss=0.9394]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▎      | 98/292 [01:44<03:35,  1.11s/batch, auc=0.6819, loss=1.0694]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▍      | 99/292 [01:44<03:34,  1.11s/batch, auc=0.6819, loss=1.0694]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▍      | 99/292 [01:45<03:34,  1.11s/batch, auc=0.6809, loss=0.8774]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▍      | 100/292 [01:45<03:33,  1.11s/batch, auc=0.6809, loss=0.8774]\u001b[A\n",
      "Training Epoch 1/1:  34%|███▍      | 100/292 [01:46<03:33,  1.11s/batch, auc=0.6809, loss=0.9895]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▍      | 101/292 [01:46<03:32,  1.11s/batch, auc=0.6809, loss=0.9895]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▍      | 101/292 [01:47<03:32,  1.11s/batch, auc=0.6795, loss=0.9132]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▍      | 102/292 [01:47<03:31,  1.11s/batch, auc=0.6795, loss=0.9132]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▍      | 102/292 [01:48<03:31,  1.11s/batch, auc=0.6801, loss=1.0566]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▌      | 103/292 [01:48<03:30,  1.12s/batch, auc=0.6801, loss=1.0566]\u001b[A\n",
      "Training Epoch 1/1:  35%|███▌      | 103/292 [01:49<03:30,  1.12s/batch, auc=0.6793, loss=0.9265]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▌      | 104/292 [01:49<03:29,  1.12s/batch, auc=0.6793, loss=0.9265]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▌      | 104/292 [01:50<03:29,  1.12s/batch, auc=0.6809, loss=0.9133]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▌      | 105/292 [01:50<03:04,  1.01batch/s, auc=0.6809, loss=0.9133]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▌      | 105/292 [01:51<03:04,  1.01batch/s, auc=0.6805, loss=1.0731]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▋      | 106/292 [01:51<03:10,  1.02s/batch, auc=0.6805, loss=1.0731]\u001b[A\n",
      "Training Epoch 1/1:  36%|███▋      | 106/292 [01:52<03:10,  1.02s/batch, auc=0.6805, loss=1.0037]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 107/292 [01:52<03:15,  1.05s/batch, auc=0.6805, loss=1.0037]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 107/292 [01:53<03:15,  1.05s/batch, auc=0.6818, loss=0.7534]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 108/292 [01:53<02:53,  1.06batch/s, auc=0.6818, loss=0.7534]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 108/292 [01:54<02:53,  1.06batch/s, auc=0.6826, loss=0.8680]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 109/292 [01:54<03:02,  1.00batch/s, auc=0.6826, loss=0.8680]\u001b[A\n",
      "Training Epoch 1/1:  37%|███▋      | 109/292 [01:55<03:02,  1.00batch/s, auc=0.6847, loss=0.8151]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 110/292 [01:55<02:44,  1.11batch/s, auc=0.6847, loss=0.8151]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 110/292 [01:56<02:44,  1.11batch/s, auc=0.6853, loss=0.8138]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 111/292 [01:56<02:54,  1.04batch/s, auc=0.6853, loss=0.8138]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 111/292 [01:57<02:54,  1.04batch/s, auc=0.6834, loss=1.1768]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 112/292 [01:57<03:01,  1.01s/batch, auc=0.6834, loss=1.1768]\u001b[A\n",
      "Training Epoch 1/1:  38%|███▊      | 112/292 [01:58<03:01,  1.01s/batch, auc=0.6851, loss=0.8388]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▊      | 113/292 [01:58<03:06,  1.04s/batch, auc=0.6851, loss=0.8388]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▊      | 113/292 [01:59<03:06,  1.04s/batch, auc=0.6864, loss=0.9113]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▉      | 114/292 [01:59<03:09,  1.07s/batch, auc=0.6864, loss=0.9113]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▉      | 114/292 [02:00<03:09,  1.07s/batch, auc=0.6860, loss=1.0670]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▉      | 115/292 [02:00<03:11,  1.08s/batch, auc=0.6860, loss=1.0670]\u001b[A\n",
      "Training Epoch 1/1:  39%|███▉      | 115/292 [02:01<03:11,  1.08s/batch, auc=0.6870, loss=0.7951]\u001b[A\n",
      "Training Epoch 1/1:  40%|███▉      | 116/292 [02:01<02:49,  1.04batch/s, auc=0.6870, loss=0.7951]\u001b[A\n",
      "Training Epoch 1/1:  40%|███▉      | 116/292 [02:02<02:49,  1.04batch/s, auc=0.6881, loss=0.8701]\u001b[A\n",
      "Training Epoch 1/1:  40%|████      | 117/292 [02:02<02:56,  1.01s/batch, auc=0.6881, loss=0.8701]\u001b[A\n",
      "Training Epoch 1/1:  40%|████      | 117/292 [02:03<02:56,  1.01s/batch, auc=0.6878, loss=0.9405]\u001b[A\n",
      "Training Epoch 1/1:  40%|████      | 118/292 [02:03<03:01,  1.04s/batch, auc=0.6878, loss=0.9405]\u001b[A\n",
      "Training Epoch 1/1:  40%|████      | 118/292 [02:04<03:01,  1.04s/batch, auc=0.6882, loss=0.8642]\u001b[A\n",
      "Training Epoch 1/1:  41%|████      | 119/292 [02:04<03:04,  1.07s/batch, auc=0.6882, loss=0.8642]\u001b[A\n",
      "Training Epoch 1/1:  41%|████      | 119/292 [02:05<03:04,  1.07s/batch, auc=0.6894, loss=0.9231]\u001b[A\n",
      "Training Epoch 1/1:  41%|████      | 120/292 [02:05<03:06,  1.08s/batch, auc=0.6894, loss=0.9231]\u001b[A\n",
      "Training Epoch 1/1:  41%|████      | 120/292 [02:06<03:06,  1.08s/batch, auc=0.6890, loss=0.9714]\u001b[A\n",
      "Training Epoch 1/1:  41%|████▏     | 121/292 [02:06<03:07,  1.10s/batch, auc=0.6890, loss=0.9714]\u001b[A\n",
      "Training Epoch 1/1:  41%|████▏     | 121/292 [02:07<03:07,  1.10s/batch, auc=0.6905, loss=0.7228]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 122/292 [02:07<02:45,  1.03batch/s, auc=0.6905, loss=0.7228]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 122/292 [02:08<02:45,  1.03batch/s, auc=0.6900, loss=0.8917]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 123/292 [02:08<02:55,  1.04s/batch, auc=0.6900, loss=0.8917]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 123/292 [02:09<02:55,  1.04s/batch, auc=0.6907, loss=0.9854]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 124/292 [02:09<02:58,  1.06s/batch, auc=0.6907, loss=0.9854]\u001b[A\n",
      "Training Epoch 1/1:  42%|████▏     | 124/292 [02:11<02:58,  1.06s/batch, auc=0.6918, loss=0.8868]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 125/292 [02:11<03:00,  1.08s/batch, auc=0.6918, loss=0.8868]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 125/292 [02:12<03:00,  1.08s/batch, auc=0.6913, loss=1.0518]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 126/292 [02:12<03:01,  1.09s/batch, auc=0.6913, loss=1.0518]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 126/292 [02:12<03:01,  1.09s/batch, auc=0.6916, loss=0.9214]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 127/292 [02:12<02:40,  1.03batch/s, auc=0.6916, loss=0.9214]\u001b[A\n",
      "Training Epoch 1/1:  43%|████▎     | 127/292 [02:13<02:40,  1.03batch/s, auc=0.6921, loss=0.9354]\u001b[A\n",
      "Training Epoch 1/1:  44%|████▍     | 128/292 [02:13<02:46,  1.01s/batch, auc=0.6921, loss=0.9354]\u001b[A\n",
      "Training Epoch 1/1:  44%|████▍     | 128/292 [02:15<02:46,  1.01s/batch, auc=0.6927, loss=0.9129]\u001b[A\n",
      "Training Epoch 1/1:  44%|████▍     | 129/292 [02:15<02:50,  1.05s/batch, auc=0.6927, loss=0.9129]\u001b[A\n",
      "Training Epoch 1/1:  44%|████▍     | 129/292 [02:16<02:50,  1.05s/batch, auc=0.6923, loss=1.1093]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▍     | 130/292 [02:16<02:52,  1.07s/batch, auc=0.6923, loss=1.1093]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▍     | 130/292 [02:17<02:52,  1.07s/batch, auc=0.6928, loss=0.9808]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▍     | 131/292 [02:17<02:54,  1.08s/batch, auc=0.6928, loss=0.9808]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▍     | 131/292 [02:17<02:54,  1.08s/batch, auc=0.6942, loss=0.9766]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▌     | 132/292 [02:17<02:34,  1.04batch/s, auc=0.6942, loss=0.9766]\u001b[A\n",
      "Training Epoch 1/1:  45%|████▌     | 132/292 [02:19<02:34,  1.04batch/s, auc=0.6946, loss=0.9741]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 133/292 [02:19<02:40,  1.01s/batch, auc=0.6946, loss=0.9741]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 133/292 [02:20<02:40,  1.01s/batch, auc=0.6944, loss=0.8332]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 134/292 [02:20<02:44,  1.04s/batch, auc=0.6944, loss=0.8332]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 134/292 [02:21<02:44,  1.04s/batch, auc=0.6939, loss=1.0067]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 135/292 [02:21<02:46,  1.06s/batch, auc=0.6939, loss=1.0067]\u001b[A\n",
      "Training Epoch 1/1:  46%|████▌     | 135/292 [02:22<02:46,  1.06s/batch, auc=0.6944, loss=0.8754]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 136/292 [02:22<02:48,  1.08s/batch, auc=0.6944, loss=0.8754]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 136/292 [02:23<02:48,  1.08s/batch, auc=0.6944, loss=0.9786]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 137/292 [02:23<02:49,  1.09s/batch, auc=0.6944, loss=0.9786]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 137/292 [02:24<02:49,  1.09s/batch, auc=0.6941, loss=1.2199]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 138/292 [02:24<02:49,  1.10s/batch, auc=0.6941, loss=1.2199]\u001b[A\n",
      "Training Epoch 1/1:  47%|████▋     | 138/292 [02:25<02:49,  1.10s/batch, auc=0.6954, loss=0.8113]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 139/292 [02:25<02:49,  1.10s/batch, auc=0.6954, loss=0.8113]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 139/292 [02:26<02:49,  1.10s/batch, auc=0.6957, loss=0.8572]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 140/292 [02:26<02:48,  1.11s/batch, auc=0.6957, loss=0.8572]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 140/292 [02:28<02:48,  1.11s/batch, auc=0.6964, loss=0.9454]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 141/292 [02:28<02:47,  1.11s/batch, auc=0.6964, loss=0.9454]\u001b[A\n",
      "Training Epoch 1/1:  48%|████▊     | 141/292 [02:28<02:47,  1.11s/batch, auc=0.6968, loss=0.8318]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▊     | 142/292 [02:28<02:27,  1.02batch/s, auc=0.6968, loss=0.8318]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▊     | 142/292 [02:29<02:27,  1.02batch/s, auc=0.6968, loss=0.9549]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▉     | 143/292 [02:29<02:32,  1.02s/batch, auc=0.6968, loss=0.9549]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▉     | 143/292 [02:30<02:32,  1.02s/batch, auc=0.6967, loss=1.1129]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▉     | 144/292 [02:30<02:16,  1.08batch/s, auc=0.6967, loss=1.1129]\u001b[A\n",
      "Training Epoch 1/1:  49%|████▉     | 144/292 [02:31<02:16,  1.08batch/s, auc=0.6970, loss=0.9759]\u001b[A\n",
      "Training Epoch 1/1:  50%|████▉     | 145/292 [02:31<02:24,  1.02batch/s, auc=0.6970, loss=0.9759]\u001b[A\n",
      "Training Epoch 1/1:  50%|████▉     | 145/292 [02:32<02:24,  1.02batch/s, auc=0.6982, loss=0.8740]\u001b[A\n",
      "Training Epoch 1/1:  50%|█████     | 146/292 [02:32<02:29,  1.02s/batch, auc=0.6982, loss=0.8740]\u001b[A\n",
      "Training Epoch 1/1:  50%|█████     | 146/292 [02:33<02:29,  1.02s/batch, auc=0.6995, loss=0.8857]\u001b[A\n",
      "Training Epoch 1/1:  50%|█████     | 147/292 [02:33<02:13,  1.09batch/s, auc=0.6995, loss=0.8857]\u001b[A\n",
      "Training Epoch 1/1:  50%|█████     | 147/292 [02:34<02:13,  1.09batch/s, auc=0.6996, loss=0.8901]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████     | 148/292 [02:34<02:24,  1.00s/batch, auc=0.6996, loss=0.8901]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████     | 148/292 [02:35<02:24,  1.00s/batch, auc=0.6998, loss=0.8993]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████     | 149/292 [02:35<02:09,  1.10batch/s, auc=0.6998, loss=0.8993]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████     | 149/292 [02:36<02:09,  1.10batch/s, auc=0.7000, loss=0.8662]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████▏    | 150/292 [02:36<02:17,  1.03batch/s, auc=0.7000, loss=0.8662]\u001b[A\n",
      "Training Epoch 1/1:  51%|█████▏    | 150/292 [02:37<02:17,  1.03batch/s, auc=0.7010, loss=0.8519]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 151/292 [02:37<02:23,  1.02s/batch, auc=0.7010, loss=0.8519]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 151/292 [02:38<02:23,  1.02s/batch, auc=0.7014, loss=1.0278]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 152/292 [02:38<02:26,  1.05s/batch, auc=0.7014, loss=1.0278]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 152/292 [02:39<02:26,  1.05s/batch, auc=0.7014, loss=0.9782]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 153/292 [02:39<02:28,  1.07s/batch, auc=0.7014, loss=0.9782]\u001b[A\n",
      "Training Epoch 1/1:  52%|█████▏    | 153/292 [02:40<02:28,  1.07s/batch, auc=0.7006, loss=1.1231]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 154/292 [02:40<02:29,  1.08s/batch, auc=0.7006, loss=1.1231]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 154/292 [02:42<02:29,  1.08s/batch, auc=0.7017, loss=0.8917]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 155/292 [02:42<02:29,  1.09s/batch, auc=0.7017, loss=0.8917]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 155/292 [02:43<02:29,  1.09s/batch, auc=0.7020, loss=0.8939]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 156/292 [02:43<02:29,  1.10s/batch, auc=0.7020, loss=0.8939]\u001b[A\n",
      "Training Epoch 1/1:  53%|█████▎    | 156/292 [02:44<02:29,  1.10s/batch, auc=0.7022, loss=0.8685]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 157/292 [02:44<02:29,  1.11s/batch, auc=0.7022, loss=0.8685]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 157/292 [02:45<02:29,  1.11s/batch, auc=0.7026, loss=0.9483]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 158/292 [02:45<02:28,  1.11s/batch, auc=0.7026, loss=0.9483]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 158/292 [02:46<02:28,  1.11s/batch, auc=0.7038, loss=0.8305]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 159/292 [02:46<02:10,  1.02batch/s, auc=0.7038, loss=0.8305]\u001b[A\n",
      "Training Epoch 1/1:  54%|█████▍    | 159/292 [02:46<02:10,  1.02batch/s, auc=0.7043, loss=0.9573]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▍    | 160/292 [02:46<01:57,  1.12batch/s, auc=0.7043, loss=0.9573]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▍    | 160/292 [02:47<01:57,  1.12batch/s, auc=0.7054, loss=0.9057]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▌    | 161/292 [02:47<01:48,  1.20batch/s, auc=0.7054, loss=0.9057]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▌    | 161/292 [02:48<01:48,  1.20batch/s, auc=0.7063, loss=0.7806]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▌    | 162/292 [02:48<01:59,  1.09batch/s, auc=0.7063, loss=0.7806]\u001b[A\n",
      "Training Epoch 1/1:  55%|█████▌    | 162/292 [02:49<01:59,  1.09batch/s, auc=0.7050, loss=1.2565]\u001b[A\n",
      "Training Epoch 1/1:  56%|█████▌    | 163/292 [02:49<02:06,  1.02batch/s, auc=0.7050, loss=1.2565]\u001b[A\n",
      "Training Epoch 1/1:  56%|█████▌    | 163/292 [02:50<02:06,  1.02batch/s, auc=0.7055, loss=0.9636]\u001b[A\n",
      "Training Epoch 1/1:  56%|█████▌    | 164/292 [02:50<02:10,  1.02s/batch, auc=0.7055, loss=0.9636]\u001b[A\n",
      "Training Epoch 1/1:  56%|█████▌    | 164/292 [02:51<02:10,  1.02s/batch, auc=0.7059, loss=0.8379]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 165/292 [02:51<02:13,  1.05s/batch, auc=0.7059, loss=0.8379]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 165/292 [02:53<02:13,  1.05s/batch, auc=0.7058, loss=1.0153]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 166/292 [02:53<02:15,  1.07s/batch, auc=0.7058, loss=1.0153]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 166/292 [02:54<02:15,  1.07s/batch, auc=0.7065, loss=0.9612]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 167/292 [02:54<02:16,  1.09s/batch, auc=0.7065, loss=0.9612]\u001b[A\n",
      "Training Epoch 1/1:  57%|█████▋    | 167/292 [02:55<02:16,  1.09s/batch, auc=0.7068, loss=0.9520]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 168/292 [02:55<02:16,  1.10s/batch, auc=0.7068, loss=0.9520]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 168/292 [02:56<02:16,  1.10s/batch, auc=0.7068, loss=1.0027]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 169/292 [02:56<02:15,  1.11s/batch, auc=0.7068, loss=1.0027]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 169/292 [02:57<02:15,  1.11s/batch, auc=0.7076, loss=0.7682]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 170/292 [02:57<01:59,  1.02batch/s, auc=0.7076, loss=0.7682]\u001b[A\n",
      "Training Epoch 1/1:  58%|█████▊    | 170/292 [02:58<01:59,  1.02batch/s, auc=0.7074, loss=1.0511]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▊    | 171/292 [02:58<02:03,  1.02s/batch, auc=0.7074, loss=1.0511]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▊    | 171/292 [02:59<02:03,  1.02s/batch, auc=0.7075, loss=0.8857]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▉    | 172/292 [02:59<02:06,  1.05s/batch, auc=0.7075, loss=0.8857]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▉    | 172/292 [03:00<02:06,  1.05s/batch, auc=0.7065, loss=1.1034]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▉    | 173/292 [03:00<02:07,  1.07s/batch, auc=0.7065, loss=1.1034]\u001b[A\n",
      "Training Epoch 1/1:  59%|█████▉    | 173/292 [03:01<02:07,  1.07s/batch, auc=0.7079, loss=0.6695]\u001b[A\n",
      "Training Epoch 1/1:  60%|█████▉    | 174/292 [03:01<01:52,  1.05batch/s, auc=0.7079, loss=0.6695]\u001b[A\n",
      "Training Epoch 1/1:  60%|█████▉    | 174/292 [03:02<01:52,  1.05batch/s, auc=0.7072, loss=1.0866]\u001b[A\n",
      "Training Epoch 1/1:  60%|█████▉    | 175/292 [03:02<01:57,  1.01s/batch, auc=0.7072, loss=1.0866]\u001b[A\n",
      "Training Epoch 1/1:  60%|█████▉    | 175/292 [03:03<01:57,  1.01s/batch, auc=0.7071, loss=0.9211]\u001b[A\n",
      "Training Epoch 1/1:  60%|██████    | 176/292 [03:03<02:00,  1.04s/batch, auc=0.7071, loss=0.9211]\u001b[A\n",
      "Training Epoch 1/1:  60%|██████    | 176/292 [03:04<02:00,  1.04s/batch, auc=0.7074, loss=0.9822]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████    | 177/292 [03:04<02:02,  1.06s/batch, auc=0.7074, loss=0.9822]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████    | 177/292 [03:05<02:02,  1.06s/batch, auc=0.7082, loss=0.8451]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████    | 178/292 [03:05<01:48,  1.05batch/s, auc=0.7082, loss=0.8451]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████    | 178/292 [03:06<01:48,  1.05batch/s, auc=0.7096, loss=0.8160]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████▏   | 179/292 [03:06<01:53,  1.00s/batch, auc=0.7096, loss=0.8160]\u001b[A\n",
      "Training Epoch 1/1:  61%|██████▏   | 179/292 [03:07<01:53,  1.00s/batch, auc=0.7098, loss=1.0279]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 180/292 [03:07<01:56,  1.04s/batch, auc=0.7098, loss=1.0279]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 180/292 [03:08<01:56,  1.04s/batch, auc=0.7102, loss=1.0672]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 181/292 [03:08<01:43,  1.07batch/s, auc=0.7102, loss=1.0672]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 181/292 [03:09<01:43,  1.07batch/s, auc=0.7092, loss=1.0335]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 182/292 [03:09<01:48,  1.01batch/s, auc=0.7092, loss=1.0335]\u001b[A\n",
      "Training Epoch 1/1:  62%|██████▏   | 182/292 [03:10<01:48,  1.01batch/s, auc=0.7088, loss=1.0732]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 183/292 [03:10<01:51,  1.03s/batch, auc=0.7088, loss=1.0732]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 183/292 [03:11<01:51,  1.03s/batch, auc=0.7094, loss=0.9184]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 184/292 [03:11<01:53,  1.05s/batch, auc=0.7094, loss=0.9184]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 184/292 [03:12<01:53,  1.05s/batch, auc=0.7087, loss=0.8620]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 185/292 [03:12<01:54,  1.07s/batch, auc=0.7087, loss=0.8620]\u001b[A\n",
      "Training Epoch 1/1:  63%|██████▎   | 185/292 [03:13<01:54,  1.07s/batch, auc=0.7090, loss=0.9458]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▎   | 186/292 [03:13<01:55,  1.09s/batch, auc=0.7090, loss=0.9458]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▎   | 186/292 [03:14<01:55,  1.09s/batch, auc=0.7086, loss=0.9967]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▍   | 187/292 [03:14<01:55,  1.10s/batch, auc=0.7086, loss=0.9967]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▍   | 187/292 [03:15<01:55,  1.10s/batch, auc=0.7093, loss=0.9258]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▍   | 188/292 [03:15<01:55,  1.11s/batch, auc=0.7093, loss=0.9258]\u001b[A\n",
      "Training Epoch 1/1:  64%|██████▍   | 188/292 [03:17<01:55,  1.11s/batch, auc=0.7086, loss=1.1454]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▍   | 189/292 [03:17<01:54,  1.11s/batch, auc=0.7086, loss=1.1454]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▍   | 189/292 [03:18<01:54,  1.11s/batch, auc=0.7090, loss=0.9221]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▌   | 190/292 [03:18<01:53,  1.11s/batch, auc=0.7090, loss=0.9221]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▌   | 190/292 [03:19<01:53,  1.11s/batch, auc=0.7090, loss=0.8467]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▌   | 191/292 [03:19<01:52,  1.12s/batch, auc=0.7090, loss=0.8467]\u001b[A\n",
      "Training Epoch 1/1:  65%|██████▌   | 191/292 [03:20<01:52,  1.12s/batch, auc=0.7087, loss=0.9393]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▌   | 192/292 [03:20<01:51,  1.12s/batch, auc=0.7087, loss=0.9393]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▌   | 192/292 [03:21<01:51,  1.12s/batch, auc=0.7083, loss=1.0155]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▌   | 193/292 [03:21<01:50,  1.12s/batch, auc=0.7083, loss=1.0155]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▌   | 193/292 [03:22<01:50,  1.12s/batch, auc=0.7082, loss=0.8648]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▋   | 194/292 [03:22<01:49,  1.12s/batch, auc=0.7082, loss=0.8648]\u001b[A\n",
      "Training Epoch 1/1:  66%|██████▋   | 194/292 [03:23<01:49,  1.12s/batch, auc=0.7078, loss=1.0484]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 195/292 [03:23<01:48,  1.12s/batch, auc=0.7078, loss=1.0484]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 195/292 [03:24<01:48,  1.12s/batch, auc=0.7088, loss=0.6764]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 196/292 [03:24<01:47,  1.12s/batch, auc=0.7088, loss=0.6764]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 196/292 [03:26<01:47,  1.12s/batch, auc=0.7089, loss=0.8041]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 197/292 [03:26<01:46,  1.12s/batch, auc=0.7089, loss=0.8041]\u001b[A\n",
      "Training Epoch 1/1:  67%|██████▋   | 197/292 [03:26<01:46,  1.12s/batch, auc=0.7089, loss=1.0211]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 198/292 [03:26<01:33,  1.01batch/s, auc=0.7089, loss=1.0211]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 198/292 [03:27<01:33,  1.01batch/s, auc=0.7084, loss=1.1648]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 199/292 [03:27<01:35,  1.03s/batch, auc=0.7084, loss=1.1648]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 199/292 [03:29<01:35,  1.03s/batch, auc=0.7079, loss=1.1166]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 200/292 [03:29<01:37,  1.06s/batch, auc=0.7079, loss=1.1166]\u001b[A\n",
      "Training Epoch 1/1:  68%|██████▊   | 200/292 [03:30<01:37,  1.06s/batch, auc=0.7079, loss=0.9071]\u001b[A\n",
      "Training Epoch 1/1:  69%|██████▉   | 201/292 [03:30<01:38,  1.08s/batch, auc=0.7079, loss=0.9071]\u001b[A\n",
      "Training Epoch 1/1:  69%|██████▉   | 201/292 [03:31<01:38,  1.08s/batch, auc=0.7083, loss=0.8439]\u001b[A\n",
      "Training Epoch 1/1:  69%|██████▉   | 202/292 [03:31<01:38,  1.09s/batch, auc=0.7083, loss=0.8439]\u001b[A\n",
      "Training Epoch 1/1:  69%|██████▉   | 202/292 [03:32<01:38,  1.09s/batch, auc=0.7084, loss=0.9815]\u001b[A\n",
      "Training Epoch 1/1:  70%|██████▉   | 203/292 [03:32<01:37,  1.10s/batch, auc=0.7084, loss=0.9815]\u001b[A\n",
      "Training Epoch 1/1:  70%|██████▉   | 203/292 [03:33<01:37,  1.10s/batch, auc=0.7090, loss=0.8160]\u001b[A\n",
      "Training Epoch 1/1:  70%|██████▉   | 204/292 [03:33<01:26,  1.02batch/s, auc=0.7090, loss=0.8160]\u001b[A\n",
      "Training Epoch 1/1:  70%|██████▉   | 204/292 [03:34<01:26,  1.02batch/s, auc=0.7095, loss=0.9075]\u001b[A\n",
      "Training Epoch 1/1:  70%|███████   | 205/292 [03:34<01:28,  1.02s/batch, auc=0.7095, loss=0.9075]\u001b[A\n",
      "Training Epoch 1/1:  70%|███████   | 205/292 [03:35<01:28,  1.02s/batch, auc=0.7091, loss=0.9492]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 206/292 [03:35<01:30,  1.05s/batch, auc=0.7091, loss=0.9492]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 206/292 [03:36<01:30,  1.05s/batch, auc=0.7087, loss=0.9233]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 207/292 [03:36<01:31,  1.07s/batch, auc=0.7087, loss=0.9233]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 207/292 [03:37<01:31,  1.07s/batch, auc=0.7092, loss=0.7368]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 208/292 [03:37<01:20,  1.04batch/s, auc=0.7092, loss=0.7368]\u001b[A\n",
      "Training Epoch 1/1:  71%|███████   | 208/292 [03:38<01:20,  1.04batch/s, auc=0.7088, loss=1.1181]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 209/292 [03:38<01:23,  1.01s/batch, auc=0.7088, loss=1.1181]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 209/292 [03:39<01:23,  1.01s/batch, auc=0.7095, loss=0.7465]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 210/292 [03:39<01:25,  1.04s/batch, auc=0.7095, loss=0.7465]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 210/292 [03:40<01:25,  1.04s/batch, auc=0.7088, loss=1.1909]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 211/292 [03:40<01:26,  1.07s/batch, auc=0.7088, loss=1.1909]\u001b[A\n",
      "Training Epoch 1/1:  72%|███████▏  | 211/292 [03:41<01:26,  1.07s/batch, auc=0.7089, loss=1.0168]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 212/292 [03:41<01:26,  1.08s/batch, auc=0.7089, loss=1.0168]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 212/292 [03:42<01:26,  1.08s/batch, auc=0.7091, loss=0.9774]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 213/292 [03:42<01:26,  1.09s/batch, auc=0.7091, loss=0.9774]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 213/292 [03:43<01:26,  1.09s/batch, auc=0.7099, loss=0.9698]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 214/292 [03:43<01:15,  1.03batch/s, auc=0.7099, loss=0.9698]\u001b[A\n",
      "Training Epoch 1/1:  73%|███████▎  | 214/292 [03:44<01:15,  1.03batch/s, auc=0.7099, loss=1.0632]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▎  | 215/292 [03:44<01:18,  1.02s/batch, auc=0.7099, loss=1.0632]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▎  | 215/292 [03:45<01:18,  1.02s/batch, auc=0.7096, loss=1.0119]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▍  | 216/292 [03:45<01:19,  1.05s/batch, auc=0.7096, loss=1.0119]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▍  | 216/292 [03:46<01:19,  1.05s/batch, auc=0.7102, loss=0.8560]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▍  | 217/292 [03:46<01:20,  1.07s/batch, auc=0.7102, loss=0.8560]\u001b[A\n",
      "Training Epoch 1/1:  74%|███████▍  | 217/292 [03:47<01:20,  1.07s/batch, auc=0.7105, loss=0.8008]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▍  | 218/292 [03:47<01:20,  1.09s/batch, auc=0.7105, loss=0.8008]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▍  | 218/292 [03:49<01:20,  1.09s/batch, auc=0.7105, loss=1.0555]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▌  | 219/292 [03:49<01:20,  1.10s/batch, auc=0.7105, loss=1.0555]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▌  | 219/292 [03:50<01:20,  1.10s/batch, auc=0.7107, loss=0.8733]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▌  | 220/292 [03:50<01:19,  1.10s/batch, auc=0.7107, loss=0.8733]\u001b[A\n",
      "Training Epoch 1/1:  75%|███████▌  | 220/292 [03:50<01:19,  1.10s/batch, auc=0.7111, loss=0.7659]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▌  | 221/292 [03:50<01:09,  1.02batch/s, auc=0.7111, loss=0.7659]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▌  | 221/292 [03:51<01:09,  1.02batch/s, auc=0.7111, loss=0.9702]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▌  | 222/292 [03:51<01:11,  1.02s/batch, auc=0.7111, loss=0.9702]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▌  | 222/292 [03:53<01:11,  1.02s/batch, auc=0.7119, loss=0.8304]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▋  | 223/292 [03:53<01:12,  1.05s/batch, auc=0.7119, loss=0.8304]\u001b[A\n",
      "Training Epoch 1/1:  76%|███████▋  | 223/292 [03:54<01:12,  1.05s/batch, auc=0.7115, loss=0.8561]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 224/292 [03:54<01:13,  1.08s/batch, auc=0.7115, loss=0.8561]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 224/292 [03:54<01:13,  1.08s/batch, auc=0.7118, loss=0.8781]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 225/292 [03:54<01:04,  1.04batch/s, auc=0.7118, loss=0.8781]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 225/292 [03:56<01:04,  1.04batch/s, auc=0.7111, loss=1.1055]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 226/292 [03:56<01:06,  1.01s/batch, auc=0.7111, loss=1.1055]\u001b[A\n",
      "Training Epoch 1/1:  77%|███████▋  | 226/292 [03:57<01:06,  1.01s/batch, auc=0.7111, loss=0.7883]\u001b[A\n",
      "Training Epoch 1/1:  78%|███████▊  | 227/292 [03:57<01:07,  1.04s/batch, auc=0.7111, loss=0.7883]\u001b[A\n",
      "Training Epoch 1/1:  78%|███████▊  | 227/292 [03:58<01:07,  1.04s/batch, auc=0.7114, loss=0.9405]\u001b[A\n",
      "Training Epoch 1/1:  78%|███████▊  | 228/292 [03:58<01:08,  1.07s/batch, auc=0.7114, loss=0.9405]\u001b[A\n",
      "Training Epoch 1/1:  78%|███████▊  | 228/292 [03:58<01:08,  1.07s/batch, auc=0.7116, loss=0.8652]\u001b[A\n",
      "Training Epoch 1/1:  78%|███████▊  | 229/292 [03:58<01:00,  1.05batch/s, auc=0.7116, loss=0.8652]\u001b[A"
     ]
    }
   ],
   "source": [
    "# begin training\n",
    "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    all_labels, all_outputs = [], []\n",
    "\n",
    "    with tqdm(train_loader, unit=\"batch\", desc=f\"Training Epoch {epoch + 1}/{epochs}\") as pbar:\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            if gca is not None:\n",
    "                images = gca.augment(images)\n",
    "            outputs = model(images) # forward pass\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad() # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            all_labels.extend(labels.cpu().numpy()) # Collect true labels and outputs for AUROC calculation\n",
    "            all_outputs.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "            # Calculate running AUROC (updated per batch)\n",
    "            try:\n",
    "                batch_auc = roc_auc_score(np.array(all_labels), np.array(all_outputs), multi_class='ovr')\n",
    "            except ValueError:\n",
    "                batch_auc = 0.0  # Handle potential errors in AUROC calculation (e.g., single class in batch)\n",
    "            # Update pbar with current loss and AUROC\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\", auc=f\"{batch_auc:.4f}\")\n",
    "\n",
    "    # Calculate epoch-level AUROC after all batches\n",
    "    train_auc = roc_auc_score(np.array(all_labels), np.array(all_outputs), multi_class='ovr')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss, val_labels, val_outputs = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            images = gca.reconstruct(images)\n",
    "#             if gca is not None:\n",
    "#                 images = gca.augment(images)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Collect true labels and outputs for validation AUROC\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "            val_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "    # Calculate validation AUROC\n",
    "    val_auc = roc_auc_score(np.array(val_labels), np.array(val_outputs), multi_class='ovr')\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Display epoch summary\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}] \"\n",
    "        f\"Train Loss: {train_loss / len(train_loader):.4f} | Train AUROC: {train_auc:.4f} \"\n",
    "        f\"Val Loss: {val_loss:.4f} | Val AUROC: {val_auc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Usage\n",
    "    evaluate_model(model, test_loader, criterion, device) # Test the model on test dataset\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(ckpt_dir, ckpt_name))\n",
    "\n",
    "    # Log results\n",
    "    logs.append([epoch + 1, train_loss, train_auc, val_loss, val_auc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss, all_outputs, all_labels = 0.0, [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            images = gca.reconstruct(images)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            outputs = torch.sigmoid(outputs).squeeze(1).cpu().numpy()\n",
    "            labels = labels.squeeze(1).cpu().numpy()\n",
    "\n",
    "            all_outputs.extend(outputs)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    avg_loss = test_loss / len(dataloader)\n",
    "    auc = roc_auc_score(all_labels, all_outputs)\n",
    "    preds = np.array(all_outputs) > 0.5\n",
    "    acc = accuracy_score(all_labels, preds)\n",
    "\n",
    "    # Confusion matrix: [[TN, FP], [FN, TP]]\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, preds).ravel()\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f} | Test AUROC: {auc:.4f} | Test Accuracy: {acc:.4f} | FNR: {fnr:.4f}\")\n",
    "    return avg_loss, auc, acc, fnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8704 | Test AUROC: 0.7876 | Test Accuracy: 0.7281 | FNR: 0.2778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8703902733737024, 0.7876441166981818, 0.7280797101449276, 0.277822257806245)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "evaluate_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"models/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (base_model): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild the model\n",
    "model = CustomModel(base_model_name='densenet', num_classes=1).to(device)  # or 'resnet' if used\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load(\"models/model.pth\"))\n",
    "model.eval()  # Very important for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CustomDataset(csv_file='../splits/rsna_test.csv', test=True)\n",
    "test_loader = create_dataloader(test_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8701 | Test AUROC: 0.7876 | Test Accuracy: 0.7281 | FNR: 0.2778\n",
      "Test Loss: 0.8701 | Test AUROC: 0.7876 | Test Accuracy: 0.7281 | FNR: 0.2778\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_auc, test_acc, fnr = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test AUROC: {test_auc:.4f} | Test Accuracy: {test_acc:.4f} | FNR: {fnr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
